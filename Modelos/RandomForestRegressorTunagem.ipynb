{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/DataFramelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "# Adicionar a variável de frete (freight_value)\n",
    "df['freight_value'] = df['freight_value']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Preencher valores ausentes com a mediana das colunas numéricas\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# Variáveis preditoras e alvo, incluindo order_id e order_purchase_timestamp para uso futuro\n",
    "X = df[['order_id', 'order_purchase_timestamp', 'delivery_time_model', 'purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g', 'seller_zip_code_prefix', 'customer_zip_code_prefix', 'freight_value', 'price']]\n",
    "y = df['delivery_time']  # Usar delivery_time já existente\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume', 'product_weight_g', 'freight_value', 'price']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['purchase_weekday', 'purchase_month', 'purchase_hour', 'seller_zip_code_prefix', 'customer_zip_code_prefix'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo com regressor RandomForestRegressor\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Definir a grade de hiperparâmetros\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# GridSearchCV para encontrar os melhores hiperparâmetros\n",
    "grid_search = GridSearchCV(estimator=model_pipeline, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Treinar o modelo com GridSearch\n",
    "grid_search.fit(X_train.drop(columns=['order_id', 'order_purchase_timestamp', 'delivery_time_model']), y_train)\n",
    "\n",
    "# Melhor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazer previsões nos dados de teste\n",
    "y_pred = best_model.predict(X_test.drop(columns=['order_id', 'order_purchase_timestamp', 'delivery_time_model']))\n",
    "\n",
    "# Diagnóstico para verificar as previsões\n",
    "print(\"Valores de previsão extremos:\", y_pred[(y_pred < 0) | (y_pred > 365)]) \n",
    "\n",
    "# Limitar valores de previsão a um intervalo razoável, por exemplo, 0 a 365 dias (1 ano)\n",
    "y_pred = np.clip(y_pred, 0, 365)\n",
    "\n",
    "# Criar DataFrame com as previsões e os resultados reais\n",
    "df_resultado = pd.DataFrame({\n",
    "    'OrderID': X_test['order_id'].values,\n",
    "    'Delivery Time Real': y_test,\n",
    "    'Delivery Time Previsto (Antigo)': X_test['delivery_time_model'],\n",
    "    'Delivery Time Previsto (Novo)': y_pred,\n",
    "})\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'Melhores hiperparâmetros: {grid_search.best_params_}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(best_model, 'best_model_pipeline_tunado.pkl')\n",
    "\n",
    "# Salvar resultado como CSV\n",
    "df_resultado.to_csv('Data/resultado_previsoes.csv', index=False)\n",
    "\n",
    "print(\"CSV de previsões salvo com sucesso!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
