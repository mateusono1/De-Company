{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 20220.21515022603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18521.300670029792\n",
      "MAE: 105.63585213014834\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Usar ThreadPoolExecutor para treino do modelo\n",
    "def train_model(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(train_model, model_pipeline, X_train, y_train)\n",
    "    future.result()  # Esperar a conclusão do treino\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18136.803027188955\n",
      "MAE: 104.82506590254518\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume', 'product_weight_g']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Usar ThreadPoolExecutor para treino do modelo\n",
    "def train_model(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(train_model, model_pipeline, X_train, y_train)\n",
    "    future.result()  # Esperar a conclusão do treino\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18007.406524008937\n",
      "MAE: 104.4635009544379\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Função para calcular a similaridade dos prefixos de CEP\n",
    "def calculate_zip_similarity(df):\n",
    "    def compare_zip_codes(row):\n",
    "        seller_zip = str(row['seller_zip_code_prefix'])\n",
    "        customer_zip = str(row['customer_zip_code_prefix'])\n",
    "        similarity = sum(1 for s, c in zip(seller_zip, customer_zip) if s == c)\n",
    "        return similarity\n",
    "\n",
    "    df['zip_code_similarity'] = df.apply(compare_zip_codes, axis=1)\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "df = calculate_zip_similarity(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Usar ThreadPoolExecutor para treino do modelo\n",
    "def train_model(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(train_model, model_pipeline, X_train, y_train)\n",
    "    future.result()  # Esperar a conclusão do treino\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 22.170821460906105\n",
      "MAE: 3.557277797666706\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/DataFrame_final_com_juncao.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Função para calcular a similaridade dos prefixos de CEP\n",
    "def calculate_zip_similarity(df):\n",
    "    def compare_zip_codes(row):\n",
    "        seller_zip = str(row['seller_zip_code_prefix'])\n",
    "        customer_zip = str(row['customer_zip_code_prefix'])\n",
    "        similarity = sum(1 for s, c in zip(seller_zip, customer_zip) if s == c)\n",
    "        return similarity\n",
    "\n",
    "    df['zip_code_similarity'] = df.apply(compare_zip_codes, axis=1)\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "# Adicionar a variável de frete (freight_value)\n",
    "df['freight_value'] = df['freight_value']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "df = calculate_zip_similarity(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity', 'freight_value']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 86400  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity', 'freight_value']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Usar ThreadPoolExecutor para treino do modelo\n",
    "def train_model(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(train_model, model_pipeline, X_train, y_train)\n",
    "    future.result()  # Esperar a conclusão do treino\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de previsão extremos: []\n",
      "MSE: 22.62431513311583\n",
      "MAE: 3.608371056104684\n",
      "CSV de previsões salvo com sucesso!\n",
      "                            OrderID  Delivery Time Real  \\\n",
      "0  95d3783847e427ad917eba3b07c4ff2e               10.93   \n",
      "1  adb8748f912cfee84bd47f072681ba5e                5.96   \n",
      "2  767754680a13ebd92bee7405c6beea73               10.86   \n",
      "3  4703d00191e1f41e4d2f979ff7612729               17.31   \n",
      "4  dfaedd65a3ca2a4cc07753c583a535d9               12.90   \n",
      "\n",
      "   Delivery Time Previsão         PrevisaoEntrega  \n",
      "0                 11.0621 2017-06-19 18:15:41.440  \n",
      "1                  8.8163 2017-05-14 12:29:56.320  \n",
      "2                 11.0412 2018-04-28 10:13:24.680  \n",
      "3                 10.6209 2017-09-26 03:26:32.760  \n",
      "4                 12.9182 2017-07-28 20:00:53.480  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/DataFrame_final_com_juncao.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Função para calcular a similaridade dos prefixos de CEP\n",
    "def calculate_zip_similarity(df):\n",
    "    def compare_zip_codes(row):\n",
    "        seller_zip = str(row['seller_zip_code_prefix'])\n",
    "        customer_zip = str(row['customer_zip_code_prefix'])\n",
    "        similarity = sum(1 for s, c in zip(seller_zip, customer_zip) if s == c)\n",
    "        return similarity\n",
    "\n",
    "    df['zip_code_similarity'] = df.apply(compare_zip_codes, axis=1)\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "# Adicionar a variável de frete (freight_value)\n",
    "df['freight_value'] = df['freight_value']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "df = calculate_zip_similarity(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo, incluindo order_id e order_purchase_timestamp para uso futuro\n",
    "X = df[['order_id', 'order_purchase_timestamp', 'purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity', 'freight_value']]\n",
    "y = df['delivery_time']  # Usar delivery_time já existente\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity', 'freight_value']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo com regressor RandomForestRegressor\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "model_pipeline.fit(X_train.drop(columns=['order_id', 'order_purchase_timestamp']), y_train)\n",
    "\n",
    "# Fazer previsões nos dados de teste\n",
    "y_pred = model_pipeline.predict(X_test.drop(columns=['order_id', 'order_purchase_timestamp']))\n",
    "\n",
    "# Diagnóstico para verificar as previsões\n",
    "print(\"Valores de previsão extremos:\", y_pred[(y_pred < 0) | (y_pred > 365)]) \n",
    "\n",
    "# Limitar valores de previsão a um intervalo razoável, por exemplo, 0 a 365 dias (1 ano)\n",
    "y_pred = np.clip(y_pred, 0, 365)\n",
    "\n",
    "# Criar DataFrame com as previsões e os resultados reais\n",
    "df_resultado = pd.DataFrame({\n",
    "    'OrderID': X_test['order_id'].values,\n",
    "    'Delivery Time Real': y_test.values,\n",
    "    'Delivery Time Previsão': y_pred,\n",
    "    'PrevisaoEntrega': [X_test['order_purchase_timestamp'].iloc[i] + timedelta(days=pred) for i, pred in enumerate(y_pred)]\n",
    "})\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'model_pipeline.pkl')\n",
    "\n",
    "# Salvar resultado como CSV\n",
    "df_resultado.to_csv('Data/resultado_previsoes.csv', index=False)\n",
    "\n",
    "print(\"CSV de previsões salvo com sucesso!\")\n",
    "print(df_resultado.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV de previsões para o kaggle salvo com sucesso!\n",
      "                           order_id  order_metric_cycle_time\n",
      "0  cee3292f46ede6ea1dfabfcb200fcf47                   9.7652\n",
      "1  50dca53ca33b739bef09e7933e8b380e                   7.8871\n",
      "2  8087ec71e393d4dc6fc48041fe63cd51                   5.0472\n",
      "3  e6b6557ce111de79b31cc857f20ba212                  10.8820\n",
      "4  0b09c5e4c2512f627190ac55a78c35a3                  13.1273\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Função para calcular a similaridade dos prefixos de CEP\n",
    "def calculate_zip_similarity(df):\n",
    "    def compare_zip_codes(row):\n",
    "        seller_zip = str(row['seller_zip_code_prefix'])\n",
    "        customer_zip = str(row['customer_zip_code_prefix'])\n",
    "        similarity = sum(1 for s, c in zip(seller_zip, customer_zip) if s == c)\n",
    "        return similarity\n",
    "\n",
    "    df['zip_code_similarity'] = df.apply(compare_zip_codes, axis=1)\n",
    "    return df\n",
    "\n",
    "# Função para pré-processamento dos dados\n",
    "def preprocess_data(df):\n",
    "    df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "    df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "    df['product_volume'] = df['product_length_cm_x'] * df['product_height_cm_x'] * df['product_width_cm_x']\n",
    "    df['product_weight_g'] = df['product_weight_g_x']\n",
    "    df = extract_datetime_features(df)\n",
    "    df = calculate_zip_similarity(df)\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "model_pipeline = joblib.load('model_pipeline.pkl')\n",
    "\n",
    "# Carregar os novos dados\n",
    "df_new = pd.read_csv(\"Data/kaggle_enriquecido.csv\")\n",
    "df_new = preprocess_data(df_new)\n",
    "\n",
    "# Variáveis preditoras\n",
    "X_new = df_new[['order_id', 'order_purchase_timestamp', 'purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity', 'freight_value']]\n",
    "\n",
    "# Fazer previsões nos novos dados\n",
    "y_pred_new = model_pipeline.predict(X_new.drop(columns=['order_id', 'order_purchase_timestamp']))\n",
    "\n",
    "# Criar DataFrame com as previsões\n",
    "df_resultado_new = pd.DataFrame({\n",
    "    'order_id': X_new['order_id'].values,\n",
    "    'order_metric_cycle_time': y_pred_new\n",
    "})\n",
    "\n",
    "# Salvar resultado como CSV sem cabeçalhos\n",
    "df_resultado_new.to_csv('Data/resultado_previsoes_kaggle.csv', index=False)\n",
    "\n",
    "print(\"CSV de previsões para o kaggle salvo com sucesso!\")\n",
    "print(df_resultado_new.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28152.000000\n",
       "mean        10.936476\n",
       "std          3.431379\n",
       "min          2.430900\n",
       "25%          8.398900\n",
       "50%         11.341250\n",
       "75%         13.487275\n",
       "max         22.471000\n",
       "Name: Delivery Time Previsão, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultado_new = pd.read_csv('Data/resultado_previsoes_kaggle.csv')\n",
    "\n",
    "# Descrever a coluna 'Delivery Time Previsão'\n",
    "delivery_time_stats = df_resultado_new['Delivery Time Previsão'].describe()\n",
    "\n",
    "delivery_time_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas na DataFrame final: 59352\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar a DataFrame principal e a DataFrame order_items\n",
    "df_principal = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "df_order_items = pd.read_csv(\"Data/order_items.csv\")\n",
    "\n",
    "# Corrigir zip codes\n",
    "df_principal['seller_zip_code_prefix'] = df_principal['seller_zip_code_prefix'].astype(str).apply(lambda x: x.zfill(5) if len(x) == 4 else x)\n",
    "df_principal['customer_zip_code_prefix'] = df_principal['customer_zip_code_prefix'].astype(str).apply(lambda x: x.zfill(5) if len(x) == 4 else x)\n",
    "\n",
    "# Remover linhas duplicadas da DataFrame order_items com base na coluna order_id\n",
    "df_order_items_clean = df_order_items.drop_duplicates(subset=['order_id'])\n",
    "\n",
    "# Realizar o merge usando pandas\n",
    "df_final = pd.merge(df_principal, df_order_items_clean, on='order_id', how='left')\n",
    "\n",
    "# Verificar o tamanho da DataFrame final\n",
    "print(f\"Número de linhas na DataFrame final: {len(df_final)}\")\n",
    "\n",
    "df_final.to_csv(\"Data/DataFrame_final_com_juncao.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18843.643010133725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import joblib\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# GridSearchCV para encontrar os melhores hiperparâmetros\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Função para treinar um modelo com um conjunto de parâmetros\n",
    "def train_model(params):\n",
    "    model_pipeline.set_params(**params)\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    return model_pipeline\n",
    "\n",
    "# Usar ThreadPoolExecutor para paralelizar GridSearchCV\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(best_model, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "\n",
    "df_novo = extract_datetime_features(df)\n",
    "\n",
    "X_novo = df_novo[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay']]\n",
    "previsoes = modelo_carregado.predict(X_novo)\n",
    "\n",
    "df_novo['previsao_data_entrega_horas'] = previsoes\n",
    "df_novo['previsao_data_entrega'] = df_novo['order_purchase_timestamp'] + pd.to_timedelta(df_novo['previsao_data_entrega_horas'], unit='h')\n",
    "\n",
    "print(df_novo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
