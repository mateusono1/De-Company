{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 20220.21515022603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18521.300670029792\n",
      "MAE: 105.63585213014834\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Usar ThreadPoolExecutor para treino do modelo\n",
    "def train_model(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(train_model, model_pipeline, X_train, y_train)\n",
    "    future.result()  # Esperar a conclusão do treino\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18136.803027188955\n",
      "MAE: 104.82506590254518\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume', 'product_weight_g']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Usar ThreadPoolExecutor para treino do modelo\n",
    "def train_model(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(train_model, model_pipeline, X_train, y_train)\n",
    "    future.result()  # Esperar a conclusão do treino\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18007.406524008937\n",
      "MAE: 104.4635009544379\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Função para calcular a similaridade dos prefixos de CEP\n",
    "def calculate_zip_similarity(df):\n",
    "    def compare_zip_codes(row):\n",
    "        seller_zip = str(row['seller_zip_code_prefix'])\n",
    "        customer_zip = str(row['customer_zip_code_prefix'])\n",
    "        similarity = sum(1 for s, c in zip(seller_zip, customer_zip) if s == c)\n",
    "        return similarity\n",
    "\n",
    "    df['zip_code_similarity'] = df.apply(compare_zip_codes, axis=1)\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "df = calculate_zip_similarity(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Usar ThreadPoolExecutor para treino do modelo\n",
    "def train_model(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(train_model, model_pipeline, X_train, y_train)\n",
    "    future.result()  # Esperar a conclusão do treino\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12779.349752200991\n",
      "MAE: 85.40084706472277\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/DataFrame_final_com_juncao.csv\")\n",
    "\n",
    "# Pré-processamento dos Dados\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "# Função para calcular a similaridade dos prefixos de CEP\n",
    "def calculate_zip_similarity(df):\n",
    "    def compare_zip_codes(row):\n",
    "        seller_zip = str(row['seller_zip_code_prefix'])\n",
    "        customer_zip = str(row['customer_zip_code_prefix'])\n",
    "        similarity = sum(1 for s, c in zip(seller_zip, customer_zip) if s == c)\n",
    "        return similarity\n",
    "\n",
    "    df['zip_code_similarity'] = df.apply(compare_zip_codes, axis=1)\n",
    "    return df\n",
    "\n",
    "# Calcular o volume do produto\n",
    "df['product_volume'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\n",
    "\n",
    "# Adicionar a variável de frete (freight_value)\n",
    "df['freight_value'] = df['freight_value']\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "df = calculate_zip_similarity(df)\n",
    "\n",
    "# Garantir que não haja valores NaN nos dados\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity', 'freight_value']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay', 'product_volume', 'product_weight_g', 'zip_code_similarity', 'freight_value']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Usar ThreadPoolExecutor para treino do modelo\n",
    "def train_model(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(train_model, model_pipeline, X_train, y_train)\n",
    "    future.result()  # Esperar a conclusão do treino\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(model_pipeline, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas na DataFrame final: 59352\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar a DataFrame principal e a DataFrame order_items\n",
    "df_principal = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "df_order_items = pd.read_csv(\"Data/order_items.csv\")\n",
    "\n",
    "# Corrigir zip codes\n",
    "df_principal['seller_zip_code_prefix'] = df_principal['seller_zip_code_prefix'].astype(str).apply(lambda x: x.zfill(5) if len(x) == 4 else x)\n",
    "df_principal['customer_zip_code_prefix'] = df_principal['customer_zip_code_prefix'].astype(str).apply(lambda x: x.zfill(5) if len(x) == 4 else x)\n",
    "\n",
    "# Remover linhas duplicadas da DataFrame order_items com base na coluna order_id\n",
    "df_order_items_clean = df_order_items.drop_duplicates(subset=['order_id'])\n",
    "\n",
    "# Realizar o merge usando pandas\n",
    "df_final = pd.merge(df_principal, df_order_items_clean, on='order_id', how='left')\n",
    "\n",
    "# Verificar o tamanho da DataFrame final\n",
    "print(f\"Número de linhas na DataFrame final: {len(df_final)}\")\n",
    "\n",
    "df_final.to_csv(\"Data/DataFrame_final_com_juncao.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18843.643010133725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import joblib\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"Data/Dataframelimpa_sem_latlong.csv\")\n",
    "\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "# Função para extrair características de data/hora\n",
    "def extract_datetime_features(df):\n",
    "    df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "    df['approval_delay'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # em horas\n",
    "    return df\n",
    "\n",
    "df = extract_datetime_features(df)\n",
    "\n",
    "# Variáveis preditoras e alvo\n",
    "X = df[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay']]\n",
    "y = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # Prever em horas\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['approval_delay']),\n",
    "        ('cat', OneHotEncoder(), ['purchase_weekday', 'purchase_month', 'purchase_hour'])\n",
    "    ])\n",
    "\n",
    "# Pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# GridSearchCV para encontrar os melhores hiperparâmetros\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Função para treinar um modelo com um conjunto de parâmetros\n",
    "def train_model(params):\n",
    "    model_pipeline.set_params(**params)\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    return model_pipeline\n",
    "\n",
    "# Usar ThreadPoolExecutor para paralelizar GridSearchCV\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "\n",
    "# Salvar o modelo para uso futuro\n",
    "joblib.dump(best_model, 'modelo_previsao_data_entrega.pkl')\n",
    "\n",
    "# Exemplo de uso do modelo salvo em novos dados\n",
    "modelo_carregado = joblib.load('modelo_previsao_data_entrega.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "\n",
    "df_novo = extract_datetime_features(df)\n",
    "\n",
    "X_novo = df_novo[['purchase_weekday', 'purchase_month', 'purchase_hour', 'approval_delay']]\n",
    "previsoes = modelo_carregado.predict(X_novo)\n",
    "\n",
    "df_novo['previsao_data_entrega_horas'] = previsoes\n",
    "df_novo['previsao_data_entrega'] = df_novo['order_purchase_timestamp'] + pd.to_timedelta(df_novo['previsao_data_entrega_horas'], unit='h')\n",
    "\n",
    "print(df_novo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
